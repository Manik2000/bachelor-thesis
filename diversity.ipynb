{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85839d8c-f63e-4f33-8941-07cdc5b1dcf4",
   "metadata": {},
   "source": [
    "# Different base-algorithms model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e975ff40-028b-4db8-80de-0d19e56529a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import openensembles as oe\n",
    "from kmodes.kmodes import KModes\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.cluster import SpectralClustering, KMeans, AgglomerativeClustering\n",
    "from sklearn.metrics import adjusted_rand_score, silhouette_score\n",
    "from algorithms import KModesEnsemble, SpectralEnsemble, HierarchyEnsemble\n",
    "from evaluation import clustering_agreement, connectivity, jaccard\n",
    "from collections import namedtuple\n",
    "from time import perf_counter\n",
    "\n",
    "\n",
    "path = r\"C:\\Users\\Manik\\repos\\bachelor_thesis\"\n",
    "if os.getcwd() != path:\n",
    "    os.chdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4bedc25a-0222-4ca7-90dd-5dc48d5408c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset = namedtuple(\"Dataset\", \"x y k\")\n",
    "\n",
    "iris = load_iris()\n",
    "iris_ = Dataset(iris.data, iris.target, 3)\n",
    "\n",
    "cassini = pd.read_csv(\"datasets/cassini.csv\", sep=\" \")\n",
    "cassini.index = np.arange(1000)\n",
    "cassini_x = np.array(cassini[[\"x\", \"y\"]])\n",
    "cassini_y = np.array(cassini.classes)\n",
    "cassini_ = Dataset(cassini_x, cassini_y, 3)\n",
    "\n",
    "# yeast\n",
    "yeast = pd.read_csv(\"datasets/yeast.txt\", sep=\"  \", header=None, engine=\"python\")\n",
    "yeast_y = yeast.iloc[:, -1]\n",
    "yeast_x = yeast.drop([0, 9], axis=1)\n",
    "yeast_y = LabelEncoder().fit_transform(yeast_y)\n",
    "yeast_x = np.array(yeast_x)\n",
    "\n",
    "yeast_ = Dataset(yeast_x, yeast_y, 10)\n",
    "\n",
    "my_own = np.loadtxt(\"datasets/my_own.txt\")\n",
    "my_own_x = my_own[:, :2]\n",
    "my_own_y = my_own[:, 2]\n",
    "\n",
    "my_own_ = Dataset(my_own_x, my_own_y, 5)\n",
    "\n",
    "digits = np.loadtxt(\"datasets/digits.txt\")\n",
    "digits_x = digits[:, :-1]\n",
    "digits_y = digits[:, -1]\n",
    "\n",
    "digits_ = Dataset(digits_x, digits_y, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b30e4813-b34b-414a-a161-933ae29af69f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup for diverse clusterings\n",
    "data = oe.data(pd.DataFrame(iris_.x), range(iris_.x.shape[1]))\n",
    "c = oe.cluster(data)\n",
    "a = c.algorithms_available()\n",
    "paramsC = c.clustering_algorithm_parameters() \n",
    "\n",
    "algorithmsToRemove = ['DBSCAN', 'Birch', \"HDBSCAN\", \"MeanShift\", \"AffinityPropagation\", \"GaussianMixture\"]\n",
    "for algToRemove in algorithmsToRemove:\n",
    "    del a[algToRemove]\n",
    "takesLinkages = paramsC['linkage']\n",
    "takesDistances = paramsC['distance']\n",
    "takesK = paramsC['K']\n",
    "\n",
    "linkages = ['average', 'complete', 'ward', \"single\"]\n",
    "distances = ['euclidean', \"manhattan\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a355e369-3766-4cc3-94d5-0e8cd1b656bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def diverse_clustering(algo, X, K, Ks):\n",
    "    X_df = pd.DataFrame(X)\n",
    "    data = oe.data(X_df, X_df.columns)\n",
    "    c = oe.cluster(data)\n",
    "    for algorithm in list(a.keys()): \n",
    "        if algorithm in takesK:\n",
    "            for k in Ks:\n",
    "                if algorithm in takesDistances:\n",
    "                    if algorithm in takesLinkages:\n",
    "                        for linkage in linkages:\n",
    "                            if linkage == 'ward':\n",
    "                                out_name = '_'.join([\"parent\", algorithm, linkage, str(k)])\n",
    "                                c.cluster(\"parent\", algorithm, out_name, K=k, Require_Unique= True, linkage=linkage)\n",
    "                            else:\n",
    "                                for dist in distances:\n",
    "                                    out_name = '_'.join([\"parent\", algorithm, dist, linkage, str(k)])\n",
    "                                    c.cluster(\"parent\", algorithm, out_name, K=k, Require_Unique= True, linkage=linkage, distance=dist)\n",
    "                    else:\n",
    "                        for dist in distances:\n",
    "                            out_name = '_'.join([\"parent\", algorithm, dist, str(k)])\n",
    "                            c.cluster(\"parent\", algorithm, out_name, K=k, Require_Unique= True, distance=dist)\n",
    "                else:\n",
    "                    out_name = '_'.join([\"parent\", algorithm, str(k)])\n",
    "                    c.cluster(\"parent\", algorithm, out_name, K=k, Require_Unique= True)\n",
    "    if algo == \"KModesEnsemble\":\n",
    "        n = len(c.labels)\n",
    "        Y = np.zeros((X.shape[0], n))\n",
    "        clusters = list(c.labels.values())\n",
    "        for i in range(n):\n",
    "            Y[:, i] = clusters[i]\n",
    "        kmodes_ = KModes(n_clusters=K)\n",
    "        return kmodes_.fit_predict(Y)\n",
    "    else:\n",
    "        co_matrix = c.co_occurrence_matrix().co_matrix\n",
    "        if algo == \"SpectralEnsemble\":\n",
    "            spec = SpectralClustering(n_clusters=K, affinity=\"precomputed\").fit(co_matrix)\n",
    "            return spec.labels_\n",
    "        hc = AgglomerativeClustering(n_clusters=K, affinity=\"precomputed\", linkage=\"average\").fit(1 - co_matrix)\n",
    "        return hc.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d1cdeb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_stability(X, est, Ks, n_iter=20, random_seed=50, **params):\n",
    "    data, k = X.x, X.k\n",
    "    np.random.seed(random_seed)\n",
    "    initial_cluster = diverse_clustering(est, data, k, Ks)\n",
    "    nrow = data.shape[0]\n",
    "    indices = np.arange(nrow)\n",
    "    scores = []\n",
    "    for i in range(n_iter):\n",
    "        sample_indices = np.random.randint(0, nrow, nrow)\n",
    "        X_bootstrap = data[sample_indices]\n",
    "        bootstrap_labels = diverse_clustering(est, X_bootstrap, k, Ks)\n",
    "        relabel = -np.ones(nrow)\n",
    "        relabel[sample_indices] = bootstrap_labels\n",
    "        in_both = np.intersect1d(indices, sample_indices)\n",
    "        scores.append(jaccard(initial_cluster[in_both], relabel[in_both]))\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d500f38-b905-4170-89ad-02b1b64fc733",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_diverse(dataset, algorithm, Ks, reps=20, seed=50):\n",
    "    data_x, k, true_labels = dataset.x, dataset.k, dataset.y\n",
    "    np.random.seed(seed)\n",
    "    clusters = []\n",
    "    agreement_indexes = []\n",
    "    rand_indexes = []\n",
    "    silhouetes_indexes = []\n",
    "    connectivity_indexes = []\n",
    "    times = []\n",
    "    for i in range(reps):\n",
    "        start = perf_counter()\n",
    "        labels = diverse_clustering(algorithm, data_x, k, Ks)\n",
    "        end = perf_counter()\n",
    "        times.append(end - start)\n",
    "        clusters.append([int(label) for label in labels])\n",
    "        agreement_indexes.append(clustering_agreement(true_labels, labels))\n",
    "        rand_indexes.append(adjusted_rand_score(true_labels, labels))\n",
    "        silhouetes_indexes.append(silhouette_score(data_x, labels))\n",
    "        connectivity_indexes.append(connectivity(data_x, labels))\n",
    "    return {\n",
    "        \"labels\": clusters,\n",
    "        \"agreement\": agreement_indexes,\n",
    "        \"rand\": rand_indexes,\n",
    "        \"silhouette\": silhouetes_indexes,\n",
    "        \"connectivity\": connectivity_indexes,\n",
    "        \"stability\": cluster_stability(dataset, algorithm, Ks),\n",
    "        \"time\": times\n",
    "           }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ddae42f-386e-45f2-a92b-2cd8172621ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "algos = [\"SpectralEnsemble\", \"HierarchicalEnsemble\", \"KModesEnsemble\"]\n",
    "\n",
    "def evaluate_final(dataset, name, Ks):\n",
    "    for (algo_name, ks) in zip(algos, Ks):\n",
    "        res = evaluate_diverse(dataset, algo_name, ks)\n",
    "        with open(f\"diversity/{name}_{algo_name}.json\", \"w\") as write_file:\n",
    "            json.dump(res, write_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "3edc3879-9a66-4539-9a2b-099ca4116922",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_final(iris_, \"iris\", [list(range(3, 10)) for i in range(3)])\n",
    "evaluate_final(my_own_, \"my_own\", [list(range(5, 7)), list(range(5, 7)), list(range(5, 10))])\n",
    "evaluate_final(cassini_, \"cassini\", [list(range(3, 6)) for i in range(3)])\n",
    "evaluate_final(yeast_, \"yeast\", [list(range(10, 15)) for i in range(3)])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ensembles",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "73b7d1a5c0ff7345001eea6d6490c413ce29469717f5d2829bb88506e05ec176"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
